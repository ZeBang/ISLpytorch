{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f9203c",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ZeBang/pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc932ca",
   "metadata": {},
   "source": [
    "Good References for Pytorch:\n",
    "    \n",
    "Deep Learning with PyTorch: A 60 Minute Blitz\n",
    "https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "\n",
    "PyTorch Fundamentals by Microsoft\n",
    "https://learn.microsoft.com/en-us/training/paths/pytorch-fundamentals/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643582ea",
   "metadata": {},
   "source": [
    "## A single Layer Network on the Hitters Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e39fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60add11",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb4a9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gitters = pd.read_csv('Gitters.csv')\n",
    "n = Gitters.shape[0]\n",
    "random.seed(13)\n",
    "ntest = math.trunc(n / 3)\n",
    "testid = random.sample(range(n), ntest)\n",
    "trainid = [i for i in range(n) if i not in testid]\n",
    "x_train = torch.from_numpy(Gitters.iloc[trainid,:-1].to_numpy()).float()\n",
    "y_train = torch.from_numpy(Gitters.iloc[trainid,-1].to_numpy().reshape(-1, 1)).float()\n",
    "x_test = torch.from_numpy(Gitters.iloc[testid,:-1].to_numpy()).float()\n",
    "y_test = torch.from_numpy(Gitters.iloc[testid,-1].to_numpy().reshape(-1, 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7fd2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (y_train - y_train.mean()) / np.sqrt(y_train.var())\n",
    "y_test = (y_test - y_test.mean()) / np.sqrt(y_test.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d59bd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd57ac2",
   "metadata": {},
   "source": [
    "**Build Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5764577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc9015",
   "metadata": {},
   "source": [
    "**Set Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30685fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "data_iter = load_array((x_train, y_train), batch_size)\n",
    "\n",
    "net = Net(20)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3866b44",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f754241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 7.140122\n",
      "epoch 2, loss 5.916814\n",
      "epoch 3, loss 4.766182\n",
      "epoch 4, loss 4.590686\n",
      "epoch 5, loss 4.455988\n",
      "epoch 6, loss 4.036636\n",
      "epoch 7, loss 3.968684\n",
      "epoch 8, loss 4.011201\n",
      "epoch 9, loss 4.137891\n",
      "epoch 10, loss 3.561571\n",
      "epoch 11, loss 4.553437\n",
      "epoch 12, loss 3.916849\n",
      "epoch 13, loss 3.826640\n",
      "epoch 14, loss 3.985428\n",
      "epoch 15, loss 3.309112\n",
      "epoch 16, loss 3.431372\n",
      "epoch 17, loss 3.041155\n",
      "epoch 18, loss 3.340093\n",
      "epoch 19, loss 3.124849\n",
      "epoch 20, loss 3.648586\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    loss_epoch = 0\n",
    "    for x,y in data_iter:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(net(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "    print(f'epoch {epoch + 1}, loss {loss_epoch:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1326d",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18f64a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5584160685539246"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = net(x_test)\n",
    "loss_function(pred, y_test).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89264e9e",
   "metadata": {},
   "source": [
    "## Multilayer Network on the MNIST Digit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3acf06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec711fa4",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a606e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the dataset using Pytorch Dataset\n",
    "train_dataset=torchvision.datasets.MNIST('./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset=torchvision.datasets.MNIST('./data',train=False,transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "## Data loader for further operation.\n",
    "train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100,shuffle=True)\n",
    "test_dataloader=torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351e55d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples torch.Size([100, 1, 28, 28])\n",
      "number of labels torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "## see the shape of the data data that has been passed in batch\n",
    "data=iter(train_dataloader)\n",
    "samples,labels=next(data)\n",
    "print(f\"number of samples {samples.shape}\")\n",
    "print(f\"number of labels {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1541d88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2500x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Printing Images from dataset\n",
    "plt.figure(figsize=(25,8))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(samples[i][0], 'BuPu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae56702",
   "metadata": {},
   "source": [
    "**Build Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4735b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(28*28, 256)\n",
    "        self.fc2=nn.Linear(256, 128)\n",
    "        self.fc3=nn.Linear(128, 10)\n",
    "        self.drop1 = nn.Dropout(0.4)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "    def forward(self,x):\n",
    "        x = self.drop1(F.relu(self.fc1(x)))\n",
    "        x = self.drop2(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ccf3f3",
   "metadata": {},
   "source": [
    "**Set Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed95c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "net = MNIST()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb53dbfd",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3a546d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1265.748399\n",
      "epoch 2, loss 671.170079\n",
      "epoch 3, loss 414.155360\n",
      "epoch 4, loss 336.781514\n",
      "epoch 5, loss 295.407463\n",
      "epoch 6, loss 270.320931\n",
      "epoch 7, loss 250.297567\n",
      "epoch 8, loss 234.539415\n",
      "epoch 9, loss 220.668807\n",
      "epoch 10, loss 209.686743\n",
      "epoch 11, loss 198.679632\n",
      "epoch 12, loss 189.890658\n",
      "epoch 13, loss 181.641917\n",
      "epoch 14, loss 174.975931\n",
      "epoch 15, loss 167.886870\n",
      "epoch 16, loss 161.933508\n",
      "epoch 17, loss 154.060923\n",
      "epoch 18, loss 150.028926\n",
      "epoch 19, loss 145.244806\n",
      "epoch 20, loss 139.440578\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    loss_epoch = 0\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.reshape(-1, 28*28)  # convert matrix image data into vector\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(net(images), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "    print(f'epoch {epoch + 1}, loss {loss_epoch:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b010b",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cac75b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting the accuracy of 96.0% on validation set\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct=0\n",
    "    n_samples=0\n",
    "    for images,labels in test_dataloader:\n",
    "        images=images.reshape(-1,784)\n",
    "        output=net(images)\n",
    "        labels=labels\n",
    "        _,prediction=torch.max(output,1)\n",
    "        n_samples=labels.shape[0]\n",
    "        n_correct=(prediction==labels).sum().item()\n",
    "    accuracy=(n_correct/n_samples)*100\n",
    "print(f'getting the accuracy of {accuracy}% on validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e29b09",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b1ec89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09997844",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d72011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26ac631b19e4788bb92341351e1a10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169001437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "131a366f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shrew baby  motorcycle otter\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f969b16",
   "metadata": {},
   "source": [
    "**Build Network**\n",
    "\n",
    "Same as Figure 10.8 on Page 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4fdf4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class netCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding='same')  # 3 input image channel, 6 output channels, 3x3 square convolution\n",
    "        self.conv2 = nn.Conv2d(6, 12, 3, padding='same')\n",
    "        self.conv3 = nn.Conv2d(12, 24, 3, padding='same')\n",
    "        # affine operation: y = Wx = b\n",
    "        self.fc1 = nn.Linear(24*4*4, 500)\n",
    "        self.fc2 = nn.Linear(500, 100)\n",
    "        # pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "# (4x96 and 216x500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaaf8ae",
   "metadata": {},
   "source": [
    "**Set Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "faeeb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "net = netCNN()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308b235",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "66bbe874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 53812.149960\n",
      "epoch 2, loss 43873.118951\n",
      "epoch 3, loss 37707.387898\n",
      "epoch 4, loss 34170.441369\n",
      "epoch 5, loss 31627.399753\n",
      "epoch 6, loss 29671.162925\n",
      "epoch 7, loss 27888.076325\n",
      "epoch 8, loss 26217.966709\n",
      "epoch 9, loss 24769.054906\n",
      "epoch 10, loss 23423.372727\n",
      "epoch 11, loss 22089.367554\n",
      "epoch 12, loss 21035.582232\n",
      "epoch 13, loss 19875.374408\n",
      "epoch 14, loss 19233.207716\n",
      "epoch 15, loss 18437.358082\n",
      "epoch 16, loss 17846.456480\n",
      "epoch 17, loss 17210.287618\n",
      "epoch 18, loss 16866.428960\n",
      "epoch 19, loss 16436.248216\n",
      "epoch 20, loss 16169.184950\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    loss_epoch = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        loss_epoch += loss.item()\n",
    "    print(f'epoch {epoch + 1}, loss {loss_epoch:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e4cac",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e1adcd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 27 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beeb695",
   "metadata": {},
   "source": [
    "## Using Pretrained CNN Models\n",
    "\n",
    "The ISL book introduced how to load the pretrained CNN model, resnet18, in R. Here we show how to load resnet18 in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eab85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c82ec15",
   "metadata": {},
   "source": [
    "All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n",
    "\n",
    "Heres a sample execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c1294d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10deec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch) # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b7a1941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                              ]     0 / 10472\r",
      " 78% [.............................................................                 ]  8192 / 10472\r",
      "100% [..............................................................................] 10472 / 10472"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'imagenet_classes.txt'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "# Download ImageNet labels\n",
    "url = 'https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt'\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cb04e75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.8846226930618286\n",
      "Arctic fox 0.045805007219314575\n",
      "white wolf 0.04427620768547058\n",
      "Pomeranian 0.005621352232992649\n",
      "Great Pyrenees 0.004652009811252356\n"
     ]
    }
   ],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd697a93",
   "metadata": {},
   "source": [
    "Before we move on, just let you know Pytorch support many data set and can be loaded using its own functions:\n",
    "\n",
    "If you are interested in how to load data in Pytorch, see:\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "\n",
    "## Recurrent Neural Networks\n",
    "\n",
    "More details about RNN network in Pytorch can be found:\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/\n",
    "\n",
    "The Pytorch support many text dataset:\n",
    "\n",
    "https://pytorch.org/data/beta/examples.html#text\n",
    "\n",
    "The book used IMDb Document text data. For IMDB sentiment analysis in Pytorch, we can see:\n",
    "\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis\n",
    "\n",
    "Following we showed a simple RNN with two hidden layer + ReLU, using MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b975687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eff8f9f562e4454b5696adeba319e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578a3a7e9d8740d6aab703462258314f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41b8c4c38e54ff589d10c3f4723f28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922e1ccba01e45028fc6b6e4b1321c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "RNNModel(\n",
      "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "10\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "Iteration: 500. Loss: 2.2939529418945312. Accuracy: 16.770000457763672\n",
      "Iteration: 1000. Loss: 2.291821002960205. Accuracy: 15.510000228881836\n",
      "Iteration: 1500. Loss: 2.287687301635742. Accuracy: 19.149999618530273\n",
      "Iteration: 2000. Loss: 1.8992336988449097. Accuracy: 29.59000015258789\n",
      "Iteration: 2500. Loss: 1.0615074634552002. Accuracy: 63.040000915527344\n",
      "Iteration: 3000. Loss: 0.8262807726860046. Accuracy: 70.0999984741211\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building your RNN\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
    "        # This is part of truncated backpropagation through time (BPTT)\n",
    "        out, hn = self.rnn(x, h0.detach())\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# JUST PRINTING MODEL & PARAMETERS \n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "\n",
    "# Number of steps to unroll\n",
    "seq_dim = 28  \n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        # Load images as tensors with gradient accumulation abilities\n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            model.eval()\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Resize images\n",
    "                images = images.view(-1, seq_dim, input_dim)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4b03a",
   "metadata": {},
   "source": [
    "### Sequential Models for Document Classification\n",
    "\n",
    "\n",
    "The following showed an example by AG_NEWS data,\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa8551",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd15cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "train_iter = iter(AG_NEWS(split='train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc21633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "train_iter = AG_NEWS(split='train')\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f104527",
   "metadata": {},
   "source": [
    "**Build Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e096a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1812ebf5",
   "metadata": {},
   "source": [
    "**Set Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72aa6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(split='train')\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de5ad7",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "becebc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb60249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 1782 batches | accuracy    0.720\n",
      "| epoch   1 |  1000/ 1782 batches | accuracy    0.868\n",
      "| epoch   1 |  1500/ 1782 batches | accuracy    0.883\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  6.96s | valid accuracy    0.886 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 1782 batches | accuracy    0.904\n",
      "| epoch   2 |  1000/ 1782 batches | accuracy    0.906\n",
      "| epoch   2 |  1500/ 1782 batches | accuracy    0.908\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  6.89s | valid accuracy    0.850 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 1782 batches | accuracy    0.924\n",
      "| epoch   3 |  1000/ 1782 batches | accuracy    0.929\n",
      "| epoch   3 |  1500/ 1782 batches | accuracy    0.930\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  6.80s | valid accuracy    0.908 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 1782 batches | accuracy    0.929\n",
      "| epoch   4 |  1000/ 1782 batches | accuracy    0.930\n",
      "| epoch   4 |  1500/ 1782 batches | accuracy    0.930\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  6.82s | valid accuracy    0.910 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 1782 batches | accuracy    0.932\n",
      "| epoch   5 |  1000/ 1782 batches | accuracy    0.931\n",
      "| epoch   5 |  1500/ 1782 batches | accuracy    0.930\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  6.88s | valid accuracy    0.911 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 1782 batches | accuracy    0.933\n",
      "| epoch   6 |  1000/ 1782 batches | accuracy    0.933\n",
      "| epoch   6 |  1500/ 1782 batches | accuracy    0.933\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  7.50s | valid accuracy    0.911 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 1782 batches | accuracy    0.936\n",
      "| epoch   7 |  1000/ 1782 batches | accuracy    0.935\n",
      "| epoch   7 |  1500/ 1782 batches | accuracy    0.935\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  7.45s | valid accuracy    0.910 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 1782 batches | accuracy    0.936\n",
      "| epoch   8 |  1000/ 1782 batches | accuracy    0.935\n",
      "| epoch   8 |  1500/ 1782 batches | accuracy    0.935\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  7.35s | valid accuracy    0.910 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 1782 batches | accuracy    0.936\n",
      "| epoch   9 |  1000/ 1782 batches | accuracy    0.935\n",
      "| epoch   9 |  1500/ 1782 batches | accuracy    0.936\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  7.29s | valid accuracy    0.910 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 1782 batches | accuracy    0.935\n",
      "| epoch  10 |  1000/ 1782 batches | accuracy    0.936\n",
      "| epoch  10 |  1500/ 1782 batches | accuracy    0.934\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  7.40s | valid accuracy    0.910 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dce32d",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d064225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.907\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648fe19",
   "metadata": {},
   "source": [
    "### Time Series Prediction with LSTM Using PyTorch\n",
    "\n",
    "Using Shampoo Sales Dataset and Airplane Passengers Dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d7f25",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979dc781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'threadpoolctl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\zeban\\AppData\\Local\\Temp\\ipykernel_12144\\1112987683.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\myfile\\anaconda\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\myfile\\anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m from .utils._tags import (\n\u001b[0;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\myfile\\anaconda\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m from .validation import (\n",
      "\u001b[1;32mC:\\myfile\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_packaging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'threadpoolctl'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e13e4",
   "metadata": {},
   "source": [
    "Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f217da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/shampoo.csv\", \"shampoo.csv\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "    \n",
    "url, filename = (\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\", \"airline-passengers.csv\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872890c8",
   "metadata": {},
   "source": [
    "Data Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98167187",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('airline-passengers.csv')\n",
    "#training_set = pd.read_csv('shampoo.csv')\n",
    "\n",
    "training_set = training_set.iloc[:,1:2].values\n",
    "\n",
    "plt.plot(training_set, label = 'Shampoo Sales Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4601f",
   "metadata": {},
   "source": [
    "**Build Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56585299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd80fc",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, trainY)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b764365",
   "metadata": {},
   "source": [
    "**Testing**\n",
    "\n",
    "Shampoo Sales Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.eval()\n",
    "train_predict = lstm(dataX)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = dataY.data.numpy()\n",
    "\n",
    "data_predict = sc.inverse_transform(data_predict)\n",
    "dataY_plot = sc.inverse_transform(dataY_plot)\n",
    "\n",
    "plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "plt.plot(dataY_plot)\n",
    "plt.plot(data_predict)\n",
    "plt.suptitle('Time-Series Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0273662",
   "metadata": {},
   "source": [
    "Airplane Passengers Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4407a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.eval()\n",
    "train_predict = lstm(dataX)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = dataY.data.numpy()\n",
    "\n",
    "data_predict = sc.inverse_transform(data_predict)\n",
    "dataY_plot = sc.inverse_transform(dataY_plot)\n",
    "\n",
    "plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "plt.plot(dataY_plot)\n",
    "plt.plot(data_predict)\n",
    "plt.suptitle('Time-Series Prediction')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
